{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9-t2O-K8Dkit"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2a9Kf-TiFUcy"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/fashion-mnist_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3r42TLoav9G",
        "outputId": "54b279c8-adc0-4829-ec27-c3e790672a0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUmPi4XmbJFk",
        "outputId": "99afd38b-682e-4605-f0b2-e93d981b40d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg5vyRi5FtSt",
        "outputId": "e780f2d3-865a-4dca-f927-e933f8f37a83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ca3e0089bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "BQgBatDKFd8y",
        "outputId": "42d721fa-7106-412d-cfdf-57b3f16c1ac6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      2       0       0       0       0       0       0       0       0   \n",
              "1      9       0       0       0       0       0       0       0       0   \n",
              "2      6       0       0       0       0       0       0       0       5   \n",
              "3      0       0       0       0       1       2       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "1       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "2       0  ...       0.0       0.0       0.0      30.0      43.0       0.0   \n",
              "3       0  ...       3.0       0.0       0.0       0.0       0.0       1.0   \n",
              "4       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       0.0       0.0       0.0       0.0  \n",
              "1       0.0       0.0       0.0       0.0  \n",
              "2       0.0       0.0       0.0       0.0  \n",
              "3       0.0       0.0       0.0       0.0  \n",
              "4       0.0       0.0       0.0       0.0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93608e37-1e46-41bd-92fe-2df275fdaa03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93608e37-1e46-41bd-92fe-2df275fdaa03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93608e37-1e46-41bd-92fe-2df275fdaa03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93608e37-1e46-41bd-92fe-2df275fdaa03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caloGLtkznmE",
        "outputId": "9a1acf9c-a291-4571-ab65-ec92ac5cefbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "W7__n0eQFhYB"
      },
      "outputs": [],
      "source": [
        "x = df.iloc[:,1:]\n",
        "y = df.iloc[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EFDccJADGA9V"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TIQYPmy6GQsD"
      },
      "outputs": [],
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dunm_-JiGk7e",
        "outputId": "a7c62eda-fe69-428d-abb0-8c218f77ddc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "x_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ydQfdamUGr07"
      },
      "outputs": [],
      "source": [
        "#create coustomdataset class\n",
        "class Custumdataset(Dataset):\n",
        "  def __init__(self,features,labels):\n",
        "    self.features = torch.tensor(features.values , dtype = torch.float32).reshape(-1,1,28,28)\n",
        "    self.labels = torch.tensor(labels.values, dtype =torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.features[idx],self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oBsltf8gI1FU"
      },
      "outputs": [],
      "source": [
        "test_dataset = Custumdataset(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vPlGaw1FLS67"
      },
      "outputs": [],
      "source": [
        "train_dataset = Custumdataset(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mLOVmeNuGgEf"
      },
      "outputs": [],
      "source": [
        "#nn class\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self,input_dim):\n",
        "    super().__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(input_dim, 32,kernel_size=3,padding=\"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "\n",
        "        nn.Conv2d(32,64,kernel_size=3,padding=\"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(3136,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "\n",
        "        nn.Linear(64,10)\n",
        "        )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.features(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "prXq8F5F9FZg"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "batches = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "EvkVR7aF_wNQ"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_dataset,batch_size=batches,shuffle=False,pin_memory = True)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batches,shuffle=True,pin_memory = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cOU9u2ZB8exg"
      },
      "outputs": [],
      "source": [
        "#creating a model\n",
        "model = NeuralNetwork(1)\n",
        "model = model.to(device)\n",
        "\n",
        "#loss function\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfEuqOUZAiHO",
        "outputId": "e20eeb59-e1fa-4bdf-e87a-77274421eb1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs = 1 and loss = 0.5835688702066739\n",
            "epochs = 2 and loss = 0.34612032180527846\n",
            "epochs = 3 and loss = 0.29759026967237395\n",
            "epochs = 4 and loss = 0.2597041491319736\n",
            "epochs = 5 and loss = 0.23712102209279934\n",
            "epochs = 6 and loss = 0.21549501223737993\n",
            "epochs = 7 and loss = 0.20094882647693157\n",
            "epochs = 8 and loss = 0.18546761492018898\n",
            "epochs = 9 and loss = 0.17030290497032305\n",
            "epochs = 10 and loss = 0.1579861388473461\n",
            "epochs = 11 and loss = 0.14675212792617578\n",
            "epochs = 12 and loss = 0.1363543469250823\n",
            "epochs = 13 and loss = 0.1304138589266998\n",
            "epochs = 14 and loss = 0.11806185886822641\n",
            "epochs = 15 and loss = 0.11061738199243942\n",
            "epochs = 16 and loss = 0.1043562748352997\n",
            "epochs = 17 and loss = 0.09610603086006207\n",
            "epochs = 18 and loss = 0.09114721358070771\n",
            "epochs = 19 and loss = 0.08602721942670177\n",
            "epochs = 20 and loss = 0.07933689145821457\n",
            "epochs = 21 and loss = 0.07617865304703203\n",
            "epochs = 22 and loss = 0.07047208880190738\n",
            "epochs = 23 and loss = 0.06474517304968322\n",
            "epochs = 24 and loss = 0.05893489326660832\n",
            "epochs = 25 and loss = 0.058882478051566677\n",
            "epochs = 26 and loss = 0.05089677714423548\n",
            "epochs = 27 and loss = 0.052015904925346454\n",
            "epochs = 28 and loss = 0.05131584178295452\n",
            "epochs = 29 and loss = 0.04393891867012523\n",
            "epochs = 30 and loss = 0.045620042252305815\n",
            "epochs = 31 and loss = 0.04131681856102659\n",
            "epochs = 32 and loss = 0.03960274778009625\n",
            "epochs = 33 and loss = 0.036774655712593814\n",
            "epochs = 34 and loss = 0.03669597649258018\n",
            "epochs = 35 and loss = 0.03335238965245662\n",
            "epochs = 36 and loss = 0.03690219851645816\n",
            "epochs = 37 and loss = 0.032825292476547474\n",
            "epochs = 38 and loss = 0.03034395167940723\n",
            "epochs = 39 and loss = 0.02851521374476397\n",
            "epochs = 40 and loss = 0.02729376973357042\n",
            "epochs = 41 and loss = 0.027172016152748255\n",
            "epochs = 42 and loss = 0.024986849151698454\n",
            "epochs = 43 and loss = 0.02626183652385953\n",
            "epochs = 44 and loss = 0.024706957654906242\n",
            "epochs = 45 and loss = 0.02372871218543878\n",
            "epochs = 46 and loss = 0.02336179866335442\n",
            "epochs = 47 and loss = 0.019361152288434824\n",
            "epochs = 48 and loss = 0.022167527141356003\n",
            "epochs = 49 and loss = 0.021967900312497173\n",
            "epochs = 50 and loss = 0.01956712422874413\n",
            "epochs = 51 and loss = 0.018809645536495435\n",
            "epochs = 52 and loss = 0.01842298330414754\n",
            "epochs = 53 and loss = 0.017226538073634706\n",
            "epochs = 54 and loss = 0.01862328182564124\n",
            "epochs = 55 and loss = 0.018519818493604057\n",
            "epochs = 56 and loss = 0.01713198467088417\n",
            "epochs = 57 and loss = 0.016434654299627253\n",
            "epochs = 58 and loss = 0.017525246127380645\n",
            "epochs = 59 and loss = 0.017494194622770312\n",
            "epochs = 60 and loss = 0.017432713712481927\n",
            "epochs = 61 and loss = 0.015642021920116652\n",
            "epochs = 62 and loss = 0.015868314517996016\n",
            "epochs = 63 and loss = 0.01341071554780289\n",
            "epochs = 64 and loss = 0.012821275011323451\n",
            "epochs = 65 and loss = 0.012486453234956268\n",
            "epochs = 66 and loss = 0.011810249462675605\n",
            "epochs = 67 and loss = 0.015217910770796607\n",
            "epochs = 68 and loss = 0.01205273209527445\n",
            "epochs = 69 and loss = 0.014915178340342512\n",
            "epochs = 70 and loss = 0.012608806607297709\n",
            "epochs = 71 and loss = 0.011459056895790127\n",
            "epochs = 72 and loss = 0.01543204711477237\n",
            "epochs = 73 and loss = 0.011490008507036084\n",
            "epochs = 74 and loss = 0.012766824552898015\n",
            "epochs = 75 and loss = 0.011921565910223383\n",
            "epochs = 76 and loss = 0.008837535300146755\n",
            "epochs = 77 and loss = 0.009509888619440025\n",
            "epochs = 78 and loss = 0.009444489381102244\n",
            "epochs = 79 and loss = 0.01064355709439451\n",
            "epochs = 80 and loss = 0.009808771361763623\n",
            "epochs = 81 and loss = 0.010938596531489793\n",
            "epochs = 82 and loss = 0.01134964579198595\n",
            "epochs = 83 and loss = 0.012393577762334946\n",
            "epochs = 84 and loss = 0.010551428713150169\n",
            "epochs = 85 and loss = 0.012265138297420587\n",
            "epochs = 86 and loss = 0.010513185160132915\n",
            "epochs = 87 and loss = 0.011384953440075644\n",
            "epochs = 88 and loss = 0.007633096752329872\n",
            "epochs = 89 and loss = 0.007405740141632691\n",
            "epochs = 90 and loss = 0.0069887509733730065\n",
            "epochs = 91 and loss = 0.01131184795075554\n",
            "epochs = 92 and loss = 0.010221629956047916\n",
            "epochs = 93 and loss = 0.00946497419130219\n",
            "epochs = 94 and loss = 0.00774396021871136\n",
            "epochs = 95 and loss = 0.008042571224785055\n",
            "epochs = 96 and loss = 0.008436255067538747\n",
            "epochs = 97 and loss = 0.010778400667910849\n",
            "epochs = 98 and loss = 0.010459005008687957\n",
            "epochs = 99 and loss = 0.00925883400141716\n",
            "epochs = 100 and loss = 0.007968886138071715\n"
          ]
        }
      ],
      "source": [
        "#training loop\n",
        "for epoch in range(epochs) :\n",
        "  epoch_loss = 0.0\n",
        "  for batch_fertures,batch_labels in train_loader:\n",
        "\n",
        "    #moving to gpu\n",
        "    batch_fertures = batch_fertures.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    y_pred = model(batch_fertures)\n",
        "\n",
        "    #loss calculation\n",
        "    loss_value = loss(y_pred,batch_labels)\n",
        "\n",
        "    #making gradindients zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #backward pass\n",
        "    loss_value.backward()\n",
        "\n",
        "    #updating the weights and bias\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss_value.item()\n",
        "  avg = epoch_loss/len(train_loader)\n",
        "  print(f\"epochs = {epoch+1} and loss = {avg}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka8b8lwAHyH3",
        "outputId": "9e7f7b5d-a319-46fa-e536-32481a19233a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.99825\n"
          ]
        }
      ],
      "source": [
        "#evaluting on train data\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "for batch_features,batch_labels in train_loader:\n",
        "  #moving the parameter on gpu\n",
        "  batch_features = batch_features.to(device)\n",
        "  batch_labels = batch_labels.to(device)\n",
        "\n",
        "  #forward pass\n",
        "  y_pred = model(batch_features)\n",
        "\n",
        "  #finding values\n",
        "  _,predicted = torch.max(y_pred,1)\n",
        "  total += batch_labels.size(0)\n",
        "  correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "accuracy = correct/total\n",
        "print(f\"accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL_MZdDhJrvn",
        "outputId": "f9f25606-439d-405d-a744-e54af88cead0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.9156666666666666\n"
          ]
        }
      ],
      "source": [
        "#evaluating on test data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "for batch_features, batch_labels in test_loader:\n",
        "  batch_features = batch_features.to(device)\n",
        "  batch_labels = batch_labels.to(device)\n",
        "\n",
        "  y_pred=model(batch_features)\n",
        "\n",
        "  _,predicted = torch.max(y_pred,1)\n",
        "  total +=batch_labels.size(0)\n",
        "  correct +=(predicted == batch_labels).sum().item()\n",
        "\n",
        "accuracy = correct/total\n",
        "print(f\"accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "701a5185"
      },
      "source": [
        "## Check for NaNs in data\n",
        "\n",
        "### Subtask:\n",
        "Inspect `x_train` and `x_test` for any NaN values that might be causing the loss to become NaN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dce34f6"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify if NaN values are present in `x_train` and `x_test`, I will use the `.isna().sum()` method on each DataFrame. This will provide a count of NaN values per column, helping to diagnose potential issues causing loss to become NaN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa10ba06",
        "outputId": "6137a6a0-eb4f-4171-ac3b-64a196b1d8f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN values in x_train:\n",
            " 658\n",
            "NaN values in x_test:\n",
            " 0\n"
          ]
        }
      ],
      "source": [
        "print(\"NaN values in x_train:\\n\", x_train.isna().sum().sum())\n",
        "print(\"NaN values in x_test:\\n\", x_test.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8123dd96"
      },
      "source": [
        "**Reasoning**:\n",
        "Since `x_train` contains NaN values, I will fill them with 0 to ensure the data is clean and suitable for model training. This will help prevent issues like the NaN loss observed during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f052718b",
        "outputId": "c9ea6a15-882f-411a-82e2-600e732713bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN values in x_train after filling: 0\n"
          ]
        }
      ],
      "source": [
        "x_train = x_train.fillna(0)\n",
        "print(\"NaN values in x_train after filling:\", x_train.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f52a4de3"
      },
      "source": [
        "## Re-evaluate model training\n",
        "\n",
        "### Subtask:\n",
        "Retrain the model after handling NaN values and observe if the loss stabilizes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a4deb1c"
      },
      "source": [
        "**Reasoning**:\n",
        "Since `x_train` has been cleaned, I need to re-instantiate the `Custumdataset` for both training and testing datasets using the updated `x_train` and `x_test` to ensure the datasets reflect the changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08e262cd",
        "outputId": "51ab6d27-df8b-41fe-9d4b-37631df997e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custumdataset re-instantiated for training and testing.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Custumdataset(x_train,y_train)\n",
        "test_dataset = Custumdataset(x_test,y_test)\n",
        "print(\"Custumdataset re-instantiated for training and testing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b86af47"
      },
      "source": [
        "**Reasoning**:\n",
        "After re-instantiating the datasets, I will re-create the DataLoaders, re-initialize the model, loss function, and optimizer, and then rerun the training and evaluation loops to observe the impact of NaN handling on the model's performance and loss stability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "420f350e",
        "outputId": "3c680565-3eb4-48bb-b6a4-3da499b8a54d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataLoaders re-created.\n",
            "Model re-initialized and moved to device.\n",
            "Loss function re-initialized.\n",
            "Optimizer re-initialized.\n",
            "Starting retraining...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [32, 784, 3, 3], expected input[32, 1, 28, 28] to have 784 channels, but got 1 channels instead",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1930454578.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2221096306.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 784, 3, 3], expected input[32, 1, 28, 28] to have 784 channels, but got 1 channels instead"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size =32,shuffle=True,pin_memory = True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False,pin_memory = True)\n",
        "print(\"DataLoaders re-created.\")\n",
        "\n",
        "#model intialization\n",
        "model = NeuralNetwork(x_train.shape[1])\n",
        "model = model.to(device)\n",
        "print(\"Model re-initialized and moved to device.\")\n",
        "\n",
        "#loss function\n",
        "loss = nn.CrossEntropyLoss()\n",
        "print(\"Loss function re-initialized.\")\n",
        "\n",
        "#optimizer\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "print(\"Optimizer re-initialized.\")\n",
        "\n",
        "#training loop\n",
        "print(\"Starting retraining...\")\n",
        "for epoch in range(epochs):\n",
        "  batch_loss = 0.0\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    #moving features and lables on gpu before forwardpass\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    y_pred= model(batch_features)\n",
        "\n",
        "    #loss calculation\n",
        "    loss_value = loss(y_pred,batch_labels)\n",
        "    # Removed NaN check as NaNs should be handled now\n",
        "\n",
        "    #making the grad values zero n=before backward pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #backward\n",
        "    loss_value.backward()\n",
        "\n",
        "    #updating the gradient values on weight and bais\n",
        "    optimizer.step()\n",
        "    batch_loss += loss_value.item()\n",
        "\n",
        "  avg_loss = batch_loss/len(train_loader)\n",
        "  if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "    print(f\"epoch = {epoch+1} and loss = {avg_loss:.4f}\")\n",
        "print(\"Retraining complete.\")\n",
        "\n",
        "#setting model into evaluation mode\n",
        "model.eval()\n",
        "print(\"Model set to evaluation mode.\")\n",
        "\n",
        "#evaluating performance\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    for batch_features, batch_labels in test_loader:\n",
        "\n",
        "      #moving features and lables on gpu before forwardpass\n",
        "      batch_features = batch_features.to(device)\n",
        "      batch_labels = batch_labels.to(device)\n",
        "\n",
        "      output = model(batch_features)\n",
        "\n",
        "      _,predicted = torch.max(output,1)\n",
        "      total += batch_labels.size(0)\n",
        "      correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "accuracy = correct/total\n",
        "print(f\"accuracy = {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-ISipjLhv0i",
        "outputId": "03b9a7e4-f9fd-4814-f410-0b03879fee4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5682, 784)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape[:]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-t2O-K8Dkit"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/fashion-mnist_train.csv')"
      ],
      "metadata": {
        "id": "2a9Kf-TiFUcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3r42TLoav9G",
        "outputId": "ad575e5f-fe98-4a5d-fd0a-c6e3a474bc0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUmPi4XmbJFk",
        "outputId": "e2eabbc0-e9a0-44dd-b333-06aa7ac81114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg5vyRi5FtSt",
        "outputId": "bf0b8eaf-7e3d-4eaf-f221-dd542ccd137c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff1ef75da70>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "BQgBatDKFd8y",
        "outputId": "fc17fb3b-bd59-4885-9300-c2904cccee45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      2       0       0       0       0       0       0       0       0   \n",
              "1      9       0       0       0       0       0       0       0       0   \n",
              "2      6       0       0       0       0       0       0       0       5   \n",
              "3      0       0       0       0       1       2       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "1       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "2       0  ...       0.0       0.0       0.0      30.0      43.0       0.0   \n",
              "3       0  ...       3.0       0.0       0.0       0.0       0.0       1.0   \n",
              "4       0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       0.0       0.0       0.0       0.0  \n",
              "1       0.0       0.0       0.0       0.0  \n",
              "2       0.0       0.0       0.0       0.0  \n",
              "3       0.0       0.0       0.0       0.0  \n",
              "4       0.0       0.0       0.0       0.0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0293b042-447b-41fb-bb3c-ccfce6384e5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0293b042-447b-41fb-bb3c-ccfce6384e5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0293b042-447b-41fb-bb3c-ccfce6384e5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0293b042-447b-41fb-bb3c-ccfce6384e5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:,1:]\n",
        "y = df.iloc[:,0]"
      ],
      "metadata": {
        "id": "W7__n0eQFhYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "EFDccJADGA9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "metadata": {
        "id": "TIQYPmy6GQsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Dunm_-JiGk7e",
        "outputId": "9bb1b4b7-517e-413f-979d-5b872120ee84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      pixel1  pixel2    pixel3  pixel4    pixel5    pixel6  pixel7    pixel8  \\\n",
              "1551     0.0     0.0  0.003922     0.0  0.000000  0.000000     0.0  0.223529   \n",
              "2957     0.0     0.0  0.000000     0.0  0.000000  0.000000     0.0  0.000000   \n",
              "6        0.0     0.0  0.000000     0.0  0.000000  0.000000     0.0  0.000000   \n",
              "3500     0.0     0.0  0.000000     0.0  0.000000  0.000000     0.0  0.000000   \n",
              "439      0.0     0.0  0.003922     0.0  0.000000  0.003922     0.0  0.000000   \n",
              "...      ...     ...       ...     ...       ...       ...     ...       ...   \n",
              "3444     0.0     0.0  0.000000     0.0  0.000000  0.000000     0.0  0.011765   \n",
              "466      0.0     0.0  0.000000     0.0  0.003922  0.000000     0.0  0.000000   \n",
              "3092     0.0     0.0  0.000000     0.0  0.000000  0.007843     0.0  0.000000   \n",
              "3772     0.0     0.0  0.000000     0.0  0.000000  0.000000     0.0  0.000000   \n",
              "860      0.0     0.0  0.000000     0.0  0.000000  0.000000     0.0  0.000000   \n",
              "\n",
              "        pixel9   pixel10  ...  pixel775  pixel776  pixel777  pixel778  \\\n",
              "1551  0.388235  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "2957  0.000000  0.015686  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "6     0.000000  0.000000  ...  0.054902  0.000000  0.000000  0.000000   \n",
              "3500  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "439   0.000000  0.058824  ...  0.215686  0.227451  0.239216  0.247059   \n",
              "...        ...       ...  ...       ...       ...       ...       ...   \n",
              "3444  0.003922  0.000000  ...  0.000000  0.000000  0.000000  0.070588   \n",
              "466   0.129412  0.494118  ...  0.478431  0.450980  0.200000  0.000000   \n",
              "3092  0.286275  0.317647  ...  0.501961  0.486275  0.317647  0.164706   \n",
              "3772  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "860   0.000000  0.000000  ...  0.000000  0.003922  0.000000  0.000000   \n",
              "\n",
              "      pixel779  pixel780  pixel781  pixel782  pixel783  pixel784  \n",
              "1551  0.000000  0.000000  0.050980       0.0       0.0       0.0  \n",
              "2957  0.572549  0.423529  0.254902       0.0       0.0       0.0  \n",
              "6     0.000000  0.000000  0.000000       0.0       0.0       0.0  \n",
              "3500  0.000000  0.000000  0.000000       0.0       0.0       0.0  \n",
              "439   0.000000  0.000000  0.003922       0.0       0.0       0.0  \n",
              "...        ...       ...       ...       ...       ...       ...  \n",
              "3444  0.439216  0.368627  0.000000       0.0       0.0       0.0  \n",
              "466   0.003922  0.000000  0.000000       0.0       0.0       0.0  \n",
              "3092  0.109804  0.000000  0.000000       0.0       0.0       0.0  \n",
              "3772  0.000000  0.000000  0.000000       0.0       0.0       0.0  \n",
              "860   0.000000  0.000000  0.000000       0.0       0.0       0.0  \n",
              "\n",
              "[3409 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afbe9717-cfa7-492c-957a-89dbacde8358\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1551</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2957</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3500</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3444</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129412</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>...</td>\n",
              "      <td>0.478431</td>\n",
              "      <td>0.450980</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3092</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.286275</td>\n",
              "      <td>0.317647</td>\n",
              "      <td>...</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.486275</td>\n",
              "      <td>0.317647</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3772</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3409 rows × 784 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afbe9717-cfa7-492c-957a-89dbacde8358')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afbe9717-cfa7-492c-957a-89dbacde8358 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afbe9717-cfa7-492c-957a-89dbacde8358');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_e36a637f-f8f3-4702-bc65-8cc8f4b358b1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e36a637f-f8f3-4702-bc65-8cc8f4b358b1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_train"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create coustomdataset class\n",
        "class Custumdataset(Dataset):\n",
        "  def __init__(self,features,labels):\n",
        "    self.features = torch.tensor(features.values , dtype = torch.float32)\n",
        "    self.labels = torch.tensor(labels.values, dtype =torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.features[idx],self.labels[idx]"
      ],
      "metadata": {
        "id": "ydQfdamUGr07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Custumdataset(x_test,y_test)"
      ],
      "metadata": {
        "id": "oBsltf8gI1FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Custumdataset(x_train,y_train)"
      ],
      "metadata": {
        "id": "vPlGaw1FLS67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size =32,shuffle=True,pin_memory = True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False,pin_memory = True)"
      ],
      "metadata": {
        "id": "-SIEwwP3JOEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nn class\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self,num_features):\n",
        "    super().__init__()\n",
        "    self.features = nn.Seq\n",
        "  def forward(self,x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "mLOVmeNuGgEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs =100\n",
        "learning_rate=0.01"
      ],
      "metadata": {
        "id": "fjJhhotCH5vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model intialization\n",
        "model = NeuralNetwork(x_train.shape[1])\n",
        "model = model.to(device)\n",
        "#loss function\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer\n",
        "optimizer = optim.(model.parameters(),lr=learning_rate,weight_decay = 1e-4)"
      ],
      "metadata": {
        "id": "olyvdmVPIXjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "for epoch in range(epochs):\n",
        "  batch_loss = 0.0\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    #moving features and lables on gpu before forwardpass\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    y_pred= model(batch_features)\n",
        "\n",
        "    #loss calculation\n",
        "    loss_value = loss(y_pred,batch_labels)\n",
        "    if torch.isnan(y_pred).any() or torch.isinf(y_pred).any():\n",
        "      print(\"NaN in model output!\")\n",
        "      break\n",
        "\n",
        "    #making the grad values zero n=before backward pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #backward\n",
        "    loss_value.backward()\n",
        "\n",
        "    #updating the gradient values on weight and bais\n",
        "    optimizer.step()\n",
        "    batch_loss += loss_value.item()\n",
        "\n",
        "  avg_loss = batch_loss/len(train_loader)\n",
        "  print(f\"epoch = {epoch+1} and loss = {avg_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gSmhsBJJipO",
        "outputId": "59058179-89da-4c98-b9af-4e78bd8a0978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 1 and loss = 1.7268100074518506\n",
            "epoch = 2 and loss = 1.2770709974743495\n",
            "epoch = 3 and loss = 1.068402029643549\n",
            "epoch = 4 and loss = 0.946195180171004\n",
            "epoch = 5 and loss = 0.8735856124173815\n",
            "epoch = 6 and loss = 0.7955507073446969\n",
            "epoch = 7 and loss = 0.7628876881621708\n",
            "epoch = 8 and loss = 0.7084722596908284\n",
            "epoch = 9 and loss = 0.6896605639257164\n",
            "epoch = 10 and loss = 0.6492937262927261\n",
            "epoch = 11 and loss = 0.6271589409525149\n",
            "epoch = 12 and loss = 0.6018012954252903\n",
            "epoch = 13 and loss = 0.5971089219935587\n",
            "epoch = 14 and loss = 0.5755350397568997\n",
            "epoch = 15 and loss = 0.5530749715377237\n",
            "epoch = 16 and loss = 0.5399435342193764\n",
            "epoch = 17 and loss = 0.5299045075880033\n",
            "epoch = 18 and loss = 0.5273990455631897\n",
            "epoch = 19 and loss = 0.5172564394284631\n",
            "epoch = 20 and loss = 0.49386685696717736\n",
            "epoch = 21 and loss = 0.49284504047621075\n",
            "epoch = 22 and loss = 0.49178702405122954\n",
            "epoch = 23 and loss = 0.48509505182226126\n",
            "epoch = 24 and loss = 0.46648275657234906\n",
            "epoch = 25 and loss = 0.44429636990355553\n",
            "epoch = 26 and loss = 0.4326676706844401\n",
            "epoch = 27 and loss = 0.44950973110221254\n",
            "epoch = 28 and loss = 0.4293201639551983\n",
            "epoch = 29 and loss = 0.42893336838650925\n",
            "epoch = 30 and loss = 0.4271990028775741\n",
            "epoch = 31 and loss = 0.3867347349073285\n",
            "epoch = 32 and loss = 0.4139937218800883\n",
            "epoch = 33 and loss = 0.3924138486106819\n",
            "epoch = 34 and loss = 0.393041981575645\n",
            "epoch = 35 and loss = 0.3802581176022503\n",
            "epoch = 36 and loss = 0.38123461242034057\n",
            "epoch = 37 and loss = 0.3646669641276386\n",
            "epoch = 38 and loss = 0.34565973254007715\n",
            "epoch = 39 and loss = 0.3633431708701303\n",
            "epoch = 40 and loss = 0.35682000164116656\n",
            "epoch = 41 and loss = 0.33748289455320235\n",
            "epoch = 42 and loss = 0.3436492124450541\n",
            "epoch = 43 and loss = 0.3506821834038351\n",
            "epoch = 44 and loss = 0.32861563075925704\n",
            "epoch = 45 and loss = 0.33891534902782083\n",
            "epoch = 46 and loss = 0.3376799666575182\n",
            "epoch = 47 and loss = 0.3142057990080842\n",
            "epoch = 48 and loss = 0.31911679238916557\n",
            "epoch = 49 and loss = 0.31654022425134604\n",
            "epoch = 50 and loss = 0.3153267555008425\n",
            "epoch = 51 and loss = 0.30392708775596083\n",
            "epoch = 52 and loss = 0.2880908399124012\n",
            "epoch = 53 and loss = 0.31125036508680504\n",
            "epoch = 54 and loss = 0.28726496470865803\n",
            "epoch = 55 and loss = 0.2775234783364234\n",
            "epoch = 56 and loss = 0.30438546787634074\n",
            "epoch = 57 and loss = 0.2772875931636195\n",
            "epoch = 58 and loss = 0.27394380643267496\n",
            "epoch = 59 and loss = 0.2914240470277929\n",
            "epoch = 60 and loss = 0.26154657989461844\n",
            "epoch = 61 and loss = 0.26437092600303275\n",
            "epoch = 62 and loss = 0.2701215874229636\n",
            "epoch = 63 and loss = 0.2630008911000234\n",
            "epoch = 64 and loss = 0.2643315400057864\n",
            "epoch = 65 and loss = 0.24993108839632194\n",
            "epoch = 66 and loss = 0.25938145001636487\n",
            "epoch = 67 and loss = 0.25842804747207143\n",
            "epoch = 68 and loss = 0.2388809103275014\n",
            "epoch = 69 and loss = 0.2636664540411156\n",
            "epoch = 70 and loss = 0.24752187958666097\n",
            "epoch = 71 and loss = 0.24646100297430965\n",
            "epoch = 72 and loss = 0.23911362350265555\n",
            "epoch = 73 and loss = 0.2249512865303833\n",
            "epoch = 74 and loss = 0.2600796523495255\n",
            "epoch = 75 and loss = 0.2211889736702509\n",
            "epoch = 76 and loss = 0.235693395973366\n",
            "epoch = 77 and loss = 0.2233065950605914\n",
            "epoch = 78 and loss = 0.23245913347351216\n",
            "epoch = 79 and loss = 0.22030402737382415\n",
            "epoch = 80 and loss = 0.22442842121714743\n",
            "epoch = 81 and loss = 0.2127135706212476\n",
            "epoch = 82 and loss = 0.1997904129256712\n",
            "epoch = 83 and loss = 0.21758065191663314\n",
            "epoch = 84 and loss = 0.21421242129301357\n",
            "epoch = 85 and loss = 0.1839235525264918\n",
            "epoch = 86 and loss = 0.20262016467401914\n",
            "epoch = 87 and loss = 0.20898266032198878\n",
            "epoch = 88 and loss = 0.2124403851611592\n",
            "epoch = 89 and loss = 0.20067339968458514\n",
            "epoch = 90 and loss = 0.1935463496527382\n",
            "epoch = 91 and loss = 0.19869140103877148\n",
            "epoch = 92 and loss = 0.19236324476861508\n",
            "epoch = 93 and loss = 0.19646814113883215\n",
            "epoch = 94 and loss = 0.20930183515231185\n",
            "epoch = 95 and loss = 0.20533828451254657\n",
            "epoch = 96 and loss = 0.20183915408136688\n",
            "epoch = 97 and loss = 0.19398164905816595\n",
            "epoch = 98 and loss = 0.1845418149344275\n",
            "epoch = 99 and loss = 0.17580054096320522\n",
            "epoch = 100 and loss = 0.19865638087286014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting model into evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpN0WJ5LUCRT",
        "outputId": "805cd83f-06d6-49e0-dd0c-95ef541fda03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.4, inplace=False)\n",
              "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating performance\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    for batch_features, batch_lables in test_loader:\n",
        "\n",
        "      #moving features and lables on gpu before forwardpass\n",
        "      batch_features = batch_features.to(device)\n",
        "      batch_labels = batch_lables.to(device) # Corrected: move the actual labels to the device\n",
        "\n",
        "      output = model(batch_features)\n",
        "\n",
        "      _,predicted = torch.max(output,1)\n",
        "      total += batch_labels.size(0)\n",
        "      correct += (predicted == batch_labels).sum().item()\n",
        "      accuracy = correct/total\n",
        "print(f\"accuracy = {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTjQTKAAXgsW",
        "outputId": "83bcfdb0-f1b3-480f-b897-7aa0328e720b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.8522860492379836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating performance\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    for batch_features, batch_lables in train_loader:\n",
        "\n",
        "      #moving features and lables on gpu before forwardpass\n",
        "      batch_features = batch_features.to(device)\n",
        "      batch_labels = batch_lables.to(device) # Corrected: move the actual labels to the device\n",
        "\n",
        "      output = model(batch_features)\n",
        "\n",
        "      _,predicted = torch.max(output,1)\n",
        "      total += batch_labels.size(0)\n",
        "      correct += (predicted == batch_labels).sum().item()\n",
        "      accuracy = correct/total\n",
        "print(f\"accuracy = {accuracy}\")"
      ],
      "metadata": {
        "id": "qjTEiVTLj7hh",
        "outputId": "a5947629-2173-4089-d59d-9bacfaeb7b20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.9779994133176885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e22a4614"
      },
      "source": [
        "# Task\n",
        "Check `x_train` and `x_test` for NaN values to identify and handle data corruption that might be causing the model's loss to become NaN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "701a5185"
      },
      "source": [
        "## Check for NaNs in data\n",
        "\n",
        "### Subtask:\n",
        "Inspect `x_train` and `x_test` for any NaN values that might be causing the loss to become NaN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dce34f6"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify if NaN values are present in `x_train` and `x_test`, I will use the `.isna().sum()` method on each DataFrame. This will provide a count of NaN values per column, helping to diagnose potential issues causing loss to become NaN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa10ba06",
        "outputId": "3631b77f-dc66-4484-a496-347b118da466"
      },
      "source": [
        "print(\"NaN values in x_train:\\n\", x_train.isna().sum().sum())\n",
        "print(\"NaN values in x_test:\\n\", x_test.isna().sum().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in x_train:\n",
            " 198\n",
            "NaN values in x_test:\n",
            " 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8123dd96"
      },
      "source": [
        "**Reasoning**:\n",
        "Since `x_train` contains NaN values, I will fill them with 0 to ensure the data is clean and suitable for model training. This will help prevent issues like the NaN loss observed during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f052718b",
        "outputId": "a5781084-e658-409b-9089-077b2016b922"
      },
      "source": [
        "x_train = x_train.fillna(0)\n",
        "print(\"NaN values in x_train after filling:\", x_train.isna().sum().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in x_train after filling: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f52a4de3"
      },
      "source": [
        "## Re-evaluate model training\n",
        "\n",
        "### Subtask:\n",
        "Retrain the model after handling NaN values and observe if the loss stabilizes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a4deb1c"
      },
      "source": [
        "**Reasoning**:\n",
        "Since `x_train` has been cleaned, I need to re-instantiate the `Custumdataset` for both training and testing datasets using the updated `x_train` and `x_test` to ensure the datasets reflect the changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08e262cd",
        "outputId": "58c8d803-0364-46e1-99b2-c1a4e173856b"
      },
      "source": [
        "train_dataset = Custumdataset(x_train,y_train)\n",
        "test_dataset = Custumdataset(x_test,y_test)\n",
        "print(\"Custumdataset re-instantiated for training and testing.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custumdataset re-instantiated for training and testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b86af47"
      },
      "source": [
        "**Reasoning**:\n",
        "After re-instantiating the datasets, I will re-create the DataLoaders, re-initialize the model, loss function, and optimizer, and then rerun the training and evaluation loops to observe the impact of NaN handling on the model's performance and loss stability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "420f350e",
        "outputId": "25ac4df4-a7dc-4f5f-f3f8-21cc14934f14"
      },
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size =32,shuffle=True,pin_memory = True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False,pin_memory = True)\n",
        "print(\"DataLoaders re-created.\")\n",
        "\n",
        "#model intialization\n",
        "model = NeuralNetwork(x_train.shape[1])\n",
        "model = model.to(device)\n",
        "print(\"Model re-initialized and moved to device.\")\n",
        "\n",
        "#loss function\n",
        "loss = nn.CrossEntropyLoss()\n",
        "print(\"Loss function re-initialized.\")\n",
        "\n",
        "#optimizer\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "print(\"Optimizer re-initialized.\")\n",
        "\n",
        "#training loop\n",
        "print(\"Starting retraining...\")\n",
        "for epoch in range(epochs):\n",
        "  batch_loss = 0.0\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    #moving features and lables on gpu before forwardpass\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    y_pred= model(batch_features)\n",
        "\n",
        "    #loss calculation\n",
        "    loss_value = loss(y_pred,batch_labels)\n",
        "    # Removed NaN check as NaNs should be handled now\n",
        "\n",
        "    #making the grad values zero n=before backward pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #backward\n",
        "    loss_value.backward()\n",
        "\n",
        "    #updating the gradient values on weight and bais\n",
        "    optimizer.step()\n",
        "    batch_loss += loss_value.item()\n",
        "\n",
        "  avg_loss = batch_loss/len(train_loader)\n",
        "  if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "    print(f\"epoch = {epoch+1} and loss = {avg_loss:.4f}\")\n",
        "print(\"Retraining complete.\")\n",
        "\n",
        "#setting model into evaluation mode\n",
        "model.eval()\n",
        "print(\"Model set to evaluation mode.\")\n",
        "\n",
        "#evaluating performance\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    for batch_features, batch_labels in test_loader:\n",
        "\n",
        "      #moving features and lables on gpu before forwardpass\n",
        "      batch_features = batch_features.to(device)\n",
        "      batch_labels = batch_labels.to(device)\n",
        "\n",
        "      output = model(batch_features)\n",
        "\n",
        "      _,predicted = torch.max(output,1)\n",
        "      total += batch_labels.size(0)\n",
        "      correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "accuracy = correct/total\n",
        "print(f\"accuracy = {accuracy:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders re-created.\n",
            "Model re-initialized and moved to device.\n",
            "Loss function re-initialized.\n",
            "Optimizer re-initialized.\n",
            "Starting retraining...\n",
            "epoch = 1 and loss = 1.2565\n",
            "epoch = 10 and loss = 0.3659\n",
            "epoch = 20 and loss = 0.2303\n",
            "epoch = 30 and loss = 0.1544\n",
            "epoch = 40 and loss = 0.0851\n",
            "epoch = 50 and loss = 0.0441\n",
            "epoch = 60 and loss = 0.0513\n",
            "epoch = 70 and loss = 0.0102\n",
            "epoch = 80 and loss = 0.0724\n",
            "epoch = 90 and loss = 0.0050\n",
            "epoch = 100 and loss = 0.0010\n",
            "Retraining complete.\n",
            "Model set to evaluation mode.\n",
            "accuracy = 0.8205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-ISipjLhv0i",
        "outputId": "eb741d2c-006b-4ce1-96ff-128bee2e3f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2648, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}